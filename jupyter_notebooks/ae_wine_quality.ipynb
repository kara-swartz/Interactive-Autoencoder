{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#loading data\n",
    "df = pd.read_csv(\"airquality.csv\", nrows = 200)\n",
    "df = df.drop(columns=['Date','Time','NMHC(GT)'])\n",
    "\n",
    "#data noramlization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(df.astype(float))\n",
    "df = pd.DataFrame(x_scaled)\n",
    "\n",
    "x_data = df.to_numpy()\n",
    "x_data = torch.Tensor(x_data).float()\n",
    "\n",
    "#batch size\n",
    "batch_size=1500\n",
    "\n",
    "EPOCH = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(12, 6),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6, 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 6),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6, 12),\n",
    "            nn.ReLU(), # compress to a range (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "autoencoder = AutoEncoder()\n",
    "loss_fun = nn.MSELoss()\n",
    "opt = torch.optim.SGD(autoencoder.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss tensor(0.2233)\n",
      "number of epoch 1 loss tensor(0.2227)\n",
      "number of epoch 2 loss tensor(0.2222)\n",
      "number of epoch 3 loss tensor(0.2216)\n",
      "number of epoch 4 loss tensor(0.2211)\n",
      "number of epoch 5 loss tensor(0.2205)\n",
      "number of epoch 6 loss tensor(0.2200)\n",
      "number of epoch 7 loss tensor(0.2195)\n",
      "number of epoch 8 loss tensor(0.2189)\n",
      "number of epoch 9 loss tensor(0.2184)\n",
      "number of epoch 10 loss tensor(0.2179)\n",
      "number of epoch 11 loss tensor(0.2174)\n",
      "number of epoch 12 loss tensor(0.2169)\n",
      "number of epoch 13 loss tensor(0.2164)\n",
      "number of epoch 14 loss tensor(0.2159)\n",
      "number of epoch 15 loss tensor(0.2154)\n",
      "number of epoch 16 loss tensor(0.2149)\n",
      "number of epoch 17 loss tensor(0.2144)\n",
      "number of epoch 18 loss tensor(0.2140)\n",
      "number of epoch 19 loss tensor(0.2135)\n",
      "number of epoch 20 loss tensor(0.2130)\n",
      "number of epoch 21 loss tensor(0.2126)\n",
      "number of epoch 22 loss tensor(0.2121)\n",
      "number of epoch 23 loss tensor(0.2117)\n",
      "number of epoch 24 loss tensor(0.2112)\n",
      "number of epoch 25 loss tensor(0.2108)\n",
      "number of epoch 26 loss tensor(0.2103)\n",
      "number of epoch 27 loss tensor(0.2099)\n",
      "number of epoch 28 loss tensor(0.2094)\n",
      "number of epoch 29 loss tensor(0.2090)\n",
      "number of epoch 30 loss tensor(0.2086)\n",
      "number of epoch 31 loss tensor(0.2082)\n",
      "number of epoch 32 loss tensor(0.2077)\n",
      "number of epoch 33 loss tensor(0.2073)\n",
      "number of epoch 34 loss tensor(0.2069)\n",
      "number of epoch 35 loss tensor(0.2065)\n",
      "number of epoch 36 loss tensor(0.2061)\n",
      "number of epoch 37 loss tensor(0.2057)\n",
      "number of epoch 38 loss tensor(0.2053)\n",
      "number of epoch 39 loss tensor(0.2049)\n",
      "number of epoch 40 loss tensor(0.2045)\n",
      "number of epoch 41 loss tensor(0.2041)\n",
      "number of epoch 42 loss tensor(0.2038)\n",
      "number of epoch 43 loss tensor(0.2034)\n",
      "number of epoch 44 loss tensor(0.2030)\n",
      "number of epoch 45 loss tensor(0.2026)\n",
      "number of epoch 46 loss tensor(0.2023)\n",
      "number of epoch 47 loss tensor(0.2019)\n",
      "number of epoch 48 loss tensor(0.2015)\n",
      "number of epoch 49 loss tensor(0.2012)\n",
      "number of epoch 50 loss tensor(0.2008)\n",
      "number of epoch 51 loss tensor(0.2005)\n",
      "number of epoch 52 loss tensor(0.2001)\n",
      "number of epoch 53 loss tensor(0.1998)\n",
      "number of epoch 54 loss tensor(0.1994)\n",
      "number of epoch 55 loss tensor(0.1991)\n",
      "number of epoch 56 loss tensor(0.1988)\n",
      "number of epoch 57 loss tensor(0.1984)\n",
      "number of epoch 58 loss tensor(0.1981)\n",
      "number of epoch 59 loss tensor(0.1978)\n",
      "number of epoch 60 loss tensor(0.1974)\n",
      "number of epoch 61 loss tensor(0.1971)\n",
      "number of epoch 62 loss tensor(0.1968)\n",
      "number of epoch 63 loss tensor(0.1965)\n",
      "number of epoch 64 loss tensor(0.1962)\n",
      "number of epoch 65 loss tensor(0.1958)\n",
      "number of epoch 66 loss tensor(0.1955)\n",
      "number of epoch 67 loss tensor(0.1952)\n",
      "number of epoch 68 loss tensor(0.1949)\n",
      "number of epoch 69 loss tensor(0.1946)\n",
      "number of epoch 70 loss tensor(0.1943)\n",
      "number of epoch 71 loss tensor(0.1940)\n",
      "number of epoch 72 loss tensor(0.1937)\n",
      "number of epoch 73 loss tensor(0.1934)\n",
      "number of epoch 74 loss tensor(0.1932)\n",
      "number of epoch 75 loss tensor(0.1929)\n",
      "number of epoch 76 loss tensor(0.1926)\n",
      "number of epoch 77 loss tensor(0.1923)\n",
      "number of epoch 78 loss tensor(0.1920)\n",
      "number of epoch 79 loss tensor(0.1918)\n",
      "number of epoch 80 loss tensor(0.1915)\n",
      "number of epoch 81 loss tensor(0.1912)\n",
      "number of epoch 82 loss tensor(0.1909)\n",
      "number of epoch 83 loss tensor(0.1907)\n",
      "number of epoch 84 loss tensor(0.1904)\n",
      "number of epoch 85 loss tensor(0.1901)\n",
      "number of epoch 86 loss tensor(0.1899)\n",
      "number of epoch 87 loss tensor(0.1896)\n",
      "number of epoch 88 loss tensor(0.1894)\n",
      "number of epoch 89 loss tensor(0.1891)\n",
      "number of epoch 90 loss tensor(0.1889)\n",
      "number of epoch 91 loss tensor(0.1886)\n",
      "number of epoch 92 loss tensor(0.1884)\n",
      "number of epoch 93 loss tensor(0.1881)\n",
      "number of epoch 94 loss tensor(0.1879)\n",
      "number of epoch 95 loss tensor(0.1876)\n",
      "number of epoch 96 loss tensor(0.1874)\n",
      "number of epoch 97 loss tensor(0.1872)\n",
      "number of epoch 98 loss tensor(0.1869)\n",
      "number of epoch 99 loss tensor(0.1867)\n",
      "number of epoch 100 loss tensor(0.1865)\n",
      "number of epoch 101 loss tensor(0.1862)\n",
      "number of epoch 102 loss tensor(0.1860)\n",
      "number of epoch 103 loss tensor(0.1858)\n",
      "number of epoch 104 loss tensor(0.1855)\n",
      "number of epoch 105 loss tensor(0.1853)\n",
      "number of epoch 106 loss tensor(0.1851)\n",
      "number of epoch 107 loss tensor(0.1849)\n",
      "number of epoch 108 loss tensor(0.1847)\n",
      "number of epoch 109 loss tensor(0.1845)\n",
      "number of epoch 110 loss tensor(0.1842)\n",
      "number of epoch 111 loss tensor(0.1840)\n",
      "number of epoch 112 loss tensor(0.1838)\n",
      "number of epoch 113 loss tensor(0.1836)\n",
      "number of epoch 114 loss tensor(0.1834)\n",
      "number of epoch 115 loss tensor(0.1832)\n",
      "number of epoch 116 loss tensor(0.1830)\n",
      "number of epoch 117 loss tensor(0.1828)\n",
      "number of epoch 118 loss tensor(0.1826)\n",
      "number of epoch 119 loss tensor(0.1824)\n",
      "number of epoch 120 loss tensor(0.1822)\n",
      "number of epoch 121 loss tensor(0.1820)\n",
      "number of epoch 122 loss tensor(0.1818)\n",
      "number of epoch 123 loss tensor(0.1816)\n",
      "number of epoch 124 loss tensor(0.1814)\n",
      "number of epoch 125 loss tensor(0.1812)\n",
      "number of epoch 126 loss tensor(0.1811)\n",
      "number of epoch 127 loss tensor(0.1809)\n",
      "number of epoch 128 loss tensor(0.1807)\n",
      "number of epoch 129 loss tensor(0.1805)\n",
      "number of epoch 130 loss tensor(0.1803)\n",
      "number of epoch 131 loss tensor(0.1801)\n",
      "number of epoch 132 loss tensor(0.1800)\n",
      "number of epoch 133 loss tensor(0.1798)\n",
      "number of epoch 134 loss tensor(0.1796)\n",
      "number of epoch 135 loss tensor(0.1794)\n",
      "number of epoch 136 loss tensor(0.1793)\n",
      "number of epoch 137 loss tensor(0.1791)\n",
      "number of epoch 138 loss tensor(0.1789)\n",
      "number of epoch 139 loss tensor(0.1788)\n",
      "number of epoch 140 loss tensor(0.1786)\n",
      "number of epoch 141 loss tensor(0.1784)\n",
      "number of epoch 142 loss tensor(0.1783)\n",
      "number of epoch 143 loss tensor(0.1781)\n",
      "number of epoch 144 loss tensor(0.1779)\n",
      "number of epoch 145 loss tensor(0.1778)\n",
      "number of epoch 146 loss tensor(0.1776)\n",
      "number of epoch 147 loss tensor(0.1775)\n",
      "number of epoch 148 loss tensor(0.1773)\n",
      "number of epoch 149 loss tensor(0.1772)\n",
      "number of epoch 150 loss tensor(0.1770)\n",
      "number of epoch 151 loss tensor(0.1769)\n",
      "number of epoch 152 loss tensor(0.1767)\n",
      "number of epoch 153 loss tensor(0.1766)\n",
      "number of epoch 154 loss tensor(0.1764)\n",
      "number of epoch 155 loss tensor(0.1763)\n",
      "number of epoch 156 loss tensor(0.1761)\n",
      "number of epoch 157 loss tensor(0.1760)\n",
      "number of epoch 158 loss tensor(0.1758)\n",
      "number of epoch 159 loss tensor(0.1757)\n",
      "number of epoch 160 loss tensor(0.1755)\n",
      "number of epoch 161 loss tensor(0.1754)\n",
      "number of epoch 162 loss tensor(0.1753)\n",
      "number of epoch 163 loss tensor(0.1751)\n",
      "number of epoch 164 loss tensor(0.1750)\n",
      "number of epoch 165 loss tensor(0.1748)\n",
      "number of epoch 166 loss tensor(0.1747)\n",
      "number of epoch 167 loss tensor(0.1746)\n",
      "number of epoch 168 loss tensor(0.1744)\n",
      "number of epoch 169 loss tensor(0.1743)\n",
      "number of epoch 170 loss tensor(0.1742)\n",
      "number of epoch 171 loss tensor(0.1740)\n",
      "number of epoch 172 loss tensor(0.1739)\n",
      "number of epoch 173 loss tensor(0.1738)\n",
      "number of epoch 174 loss tensor(0.1737)\n",
      "number of epoch 175 loss tensor(0.1735)\n",
      "number of epoch 176 loss tensor(0.1734)\n",
      "number of epoch 177 loss tensor(0.1733)\n",
      "number of epoch 178 loss tensor(0.1732)\n",
      "number of epoch 179 loss tensor(0.1730)\n",
      "number of epoch 180 loss tensor(0.1729)\n",
      "number of epoch 181 loss tensor(0.1728)\n",
      "number of epoch 182 loss tensor(0.1727)\n",
      "number of epoch 183 loss tensor(0.1726)\n",
      "number of epoch 184 loss tensor(0.1724)\n",
      "number of epoch 185 loss tensor(0.1723)\n",
      "number of epoch 186 loss tensor(0.1722)\n",
      "number of epoch 187 loss tensor(0.1721)\n",
      "number of epoch 188 loss tensor(0.1720)\n",
      "number of epoch 189 loss tensor(0.1719)\n",
      "number of epoch 190 loss tensor(0.1718)\n",
      "number of epoch 191 loss tensor(0.1717)\n",
      "number of epoch 192 loss tensor(0.1715)\n",
      "number of epoch 193 loss tensor(0.1714)\n",
      "number of epoch 194 loss tensor(0.1713)\n",
      "number of epoch 195 loss tensor(0.1712)\n",
      "number of epoch 196 loss tensor(0.1711)\n",
      "number of epoch 197 loss tensor(0.1710)\n",
      "number of epoch 198 loss tensor(0.1709)\n",
      "number of epoch 199 loss tensor(0.1708)\n",
      "number of epoch 200 loss tensor(0.1707)\n",
      "number of epoch 201 loss tensor(0.1706)\n",
      "number of epoch 202 loss tensor(0.1705)\n",
      "number of epoch 203 loss tensor(0.1704)\n",
      "number of epoch 204 loss tensor(0.1703)\n",
      "number of epoch 205 loss tensor(0.1702)\n",
      "number of epoch 206 loss tensor(0.1701)\n",
      "number of epoch 207 loss tensor(0.1700)\n",
      "number of epoch 208 loss tensor(0.1699)\n",
      "number of epoch 209 loss tensor(0.1698)\n",
      "number of epoch 210 loss tensor(0.1697)\n",
      "number of epoch 211 loss tensor(0.1696)\n",
      "number of epoch 212 loss tensor(0.1695)\n",
      "number of epoch 213 loss tensor(0.1694)\n",
      "number of epoch 214 loss tensor(0.1693)\n",
      "number of epoch 215 loss tensor(0.1692)\n",
      "number of epoch 216 loss tensor(0.1692)\n",
      "number of epoch 217 loss tensor(0.1691)\n",
      "number of epoch 218 loss tensor(0.1690)\n",
      "number of epoch 219 loss tensor(0.1689)\n",
      "number of epoch 220 loss tensor(0.1688)\n",
      "number of epoch 221 loss tensor(0.1687)\n",
      "number of epoch 222 loss tensor(0.1686)\n",
      "number of epoch 223 loss tensor(0.1685)\n",
      "number of epoch 224 loss tensor(0.1684)\n",
      "number of epoch 225 loss tensor(0.1684)\n",
      "number of epoch 226 loss tensor(0.1683)\n",
      "number of epoch 227 loss tensor(0.1682)\n",
      "number of epoch 228 loss tensor(0.1681)\n",
      "number of epoch 229 loss tensor(0.1680)\n",
      "number of epoch 230 loss tensor(0.1680)\n",
      "number of epoch 231 loss tensor(0.1679)\n",
      "number of epoch 232 loss tensor(0.1678)\n",
      "number of epoch 233 loss tensor(0.1677)\n",
      "number of epoch 234 loss tensor(0.1676)\n",
      "number of epoch 235 loss tensor(0.1676)\n",
      "number of epoch 236 loss tensor(0.1675)\n",
      "number of epoch 237 loss tensor(0.1674)\n",
      "number of epoch 238 loss tensor(0.1673)\n",
      "number of epoch 239 loss tensor(0.1672)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 240 loss tensor(0.1672)\n",
      "number of epoch 241 loss tensor(0.1671)\n",
      "number of epoch 242 loss tensor(0.1670)\n",
      "number of epoch 243 loss tensor(0.1669)\n",
      "number of epoch 244 loss tensor(0.1669)\n",
      "number of epoch 245 loss tensor(0.1668)\n",
      "number of epoch 246 loss tensor(0.1667)\n",
      "number of epoch 247 loss tensor(0.1667)\n",
      "number of epoch 248 loss tensor(0.1666)\n",
      "number of epoch 249 loss tensor(0.1665)\n",
      "number of epoch 250 loss tensor(0.1664)\n",
      "number of epoch 251 loss tensor(0.1664)\n",
      "number of epoch 252 loss tensor(0.1663)\n",
      "number of epoch 253 loss tensor(0.1662)\n",
      "number of epoch 254 loss tensor(0.1662)\n",
      "number of epoch 255 loss tensor(0.1661)\n",
      "number of epoch 256 loss tensor(0.1660)\n",
      "number of epoch 257 loss tensor(0.1660)\n",
      "number of epoch 258 loss tensor(0.1659)\n",
      "number of epoch 259 loss tensor(0.1658)\n",
      "number of epoch 260 loss tensor(0.1658)\n",
      "number of epoch 261 loss tensor(0.1657)\n",
      "number of epoch 262 loss tensor(0.1657)\n",
      "number of epoch 263 loss tensor(0.1656)\n",
      "number of epoch 264 loss tensor(0.1655)\n",
      "number of epoch 265 loss tensor(0.1655)\n",
      "number of epoch 266 loss tensor(0.1654)\n",
      "number of epoch 267 loss tensor(0.1653)\n",
      "number of epoch 268 loss tensor(0.1653)\n",
      "number of epoch 269 loss tensor(0.1652)\n",
      "number of epoch 270 loss tensor(0.1652)\n",
      "number of epoch 271 loss tensor(0.1651)\n",
      "number of epoch 272 loss tensor(0.1650)\n",
      "number of epoch 273 loss tensor(0.1650)\n",
      "number of epoch 274 loss tensor(0.1649)\n",
      "number of epoch 275 loss tensor(0.1649)\n",
      "number of epoch 276 loss tensor(0.1648)\n",
      "number of epoch 277 loss tensor(0.1648)\n",
      "number of epoch 278 loss tensor(0.1647)\n",
      "number of epoch 279 loss tensor(0.1646)\n",
      "number of epoch 280 loss tensor(0.1646)\n",
      "number of epoch 281 loss tensor(0.1645)\n",
      "number of epoch 282 loss tensor(0.1645)\n",
      "number of epoch 283 loss tensor(0.1644)\n",
      "number of epoch 284 loss tensor(0.1644)\n",
      "number of epoch 285 loss tensor(0.1643)\n",
      "number of epoch 286 loss tensor(0.1643)\n",
      "number of epoch 287 loss tensor(0.1642)\n",
      "number of epoch 288 loss tensor(0.1642)\n",
      "number of epoch 289 loss tensor(0.1641)\n",
      "number of epoch 290 loss tensor(0.1641)\n",
      "number of epoch 291 loss tensor(0.1640)\n",
      "number of epoch 292 loss tensor(0.1640)\n",
      "number of epoch 293 loss tensor(0.1639)\n",
      "number of epoch 294 loss tensor(0.1639)\n",
      "number of epoch 295 loss tensor(0.1638)\n",
      "number of epoch 296 loss tensor(0.1638)\n",
      "number of epoch 297 loss tensor(0.1637)\n",
      "number of epoch 298 loss tensor(0.1637)\n",
      "number of epoch 299 loss tensor(0.1636)\n",
      "number of epoch 300 loss tensor(0.1636)\n",
      "number of epoch 301 loss tensor(0.1635)\n",
      "number of epoch 302 loss tensor(0.1635)\n",
      "number of epoch 303 loss tensor(0.1634)\n",
      "number of epoch 304 loss tensor(0.1634)\n",
      "number of epoch 305 loss tensor(0.1633)\n",
      "number of epoch 306 loss tensor(0.1633)\n",
      "number of epoch 307 loss tensor(0.1633)\n",
      "number of epoch 308 loss tensor(0.1632)\n",
      "number of epoch 309 loss tensor(0.1632)\n",
      "number of epoch 310 loss tensor(0.1631)\n",
      "number of epoch 311 loss tensor(0.1631)\n",
      "number of epoch 312 loss tensor(0.1630)\n",
      "number of epoch 313 loss tensor(0.1630)\n",
      "number of epoch 314 loss tensor(0.1629)\n",
      "number of epoch 315 loss tensor(0.1629)\n",
      "number of epoch 316 loss tensor(0.1629)\n",
      "number of epoch 317 loss tensor(0.1628)\n",
      "number of epoch 318 loss tensor(0.1628)\n",
      "number of epoch 319 loss tensor(0.1627)\n",
      "number of epoch 320 loss tensor(0.1627)\n",
      "number of epoch 321 loss tensor(0.1627)\n",
      "number of epoch 322 loss tensor(0.1626)\n",
      "number of epoch 323 loss tensor(0.1626)\n",
      "number of epoch 324 loss tensor(0.1625)\n",
      "number of epoch 325 loss tensor(0.1625)\n",
      "number of epoch 326 loss tensor(0.1625)\n",
      "number of epoch 327 loss tensor(0.1624)\n",
      "number of epoch 328 loss tensor(0.1624)\n",
      "number of epoch 329 loss tensor(0.1624)\n",
      "number of epoch 330 loss tensor(0.1623)\n",
      "number of epoch 331 loss tensor(0.1623)\n",
      "number of epoch 332 loss tensor(0.1622)\n",
      "number of epoch 333 loss tensor(0.1622)\n",
      "number of epoch 334 loss tensor(0.1622)\n",
      "number of epoch 335 loss tensor(0.1621)\n",
      "number of epoch 336 loss tensor(0.1621)\n",
      "number of epoch 337 loss tensor(0.1621)\n",
      "number of epoch 338 loss tensor(0.1620)\n",
      "number of epoch 339 loss tensor(0.1620)\n",
      "number of epoch 340 loss tensor(0.1620)\n",
      "number of epoch 341 loss tensor(0.1619)\n",
      "number of epoch 342 loss tensor(0.1619)\n",
      "number of epoch 343 loss tensor(0.1619)\n",
      "number of epoch 344 loss tensor(0.1618)\n",
      "number of epoch 345 loss tensor(0.1618)\n",
      "number of epoch 346 loss tensor(0.1618)\n",
      "number of epoch 347 loss tensor(0.1617)\n",
      "number of epoch 348 loss tensor(0.1617)\n",
      "number of epoch 349 loss tensor(0.1617)\n",
      "number of epoch 350 loss tensor(0.1616)\n",
      "number of epoch 351 loss tensor(0.1616)\n",
      "number of epoch 352 loss tensor(0.1616)\n",
      "number of epoch 353 loss tensor(0.1615)\n",
      "number of epoch 354 loss tensor(0.1615)\n",
      "number of epoch 355 loss tensor(0.1615)\n",
      "number of epoch 356 loss tensor(0.1614)\n",
      "number of epoch 357 loss tensor(0.1614)\n",
      "number of epoch 358 loss tensor(0.1614)\n",
      "number of epoch 359 loss tensor(0.1613)\n",
      "number of epoch 360 loss tensor(0.1613)\n",
      "number of epoch 361 loss tensor(0.1613)\n",
      "number of epoch 362 loss tensor(0.1613)\n",
      "number of epoch 363 loss tensor(0.1612)\n",
      "number of epoch 364 loss tensor(0.1612)\n",
      "number of epoch 365 loss tensor(0.1612)\n",
      "number of epoch 366 loss tensor(0.1611)\n",
      "number of epoch 367 loss tensor(0.1611)\n",
      "number of epoch 368 loss tensor(0.1611)\n",
      "number of epoch 369 loss tensor(0.1611)\n",
      "number of epoch 370 loss tensor(0.1610)\n",
      "number of epoch 371 loss tensor(0.1610)\n",
      "number of epoch 372 loss tensor(0.1610)\n",
      "number of epoch 373 loss tensor(0.1609)\n",
      "number of epoch 374 loss tensor(0.1609)\n",
      "number of epoch 375 loss tensor(0.1609)\n",
      "number of epoch 376 loss tensor(0.1609)\n",
      "number of epoch 377 loss tensor(0.1608)\n",
      "number of epoch 378 loss tensor(0.1608)\n",
      "number of epoch 379 loss tensor(0.1608)\n",
      "number of epoch 380 loss tensor(0.1608)\n",
      "number of epoch 381 loss tensor(0.1607)\n",
      "number of epoch 382 loss tensor(0.1607)\n",
      "number of epoch 383 loss tensor(0.1607)\n",
      "number of epoch 384 loss tensor(0.1607)\n",
      "number of epoch 385 loss tensor(0.1606)\n",
      "number of epoch 386 loss tensor(0.1606)\n",
      "number of epoch 387 loss tensor(0.1606)\n",
      "number of epoch 388 loss tensor(0.1606)\n",
      "number of epoch 389 loss tensor(0.1605)\n",
      "number of epoch 390 loss tensor(0.1605)\n",
      "number of epoch 391 loss tensor(0.1605)\n",
      "number of epoch 392 loss tensor(0.1605)\n",
      "number of epoch 393 loss tensor(0.1605)\n",
      "number of epoch 394 loss tensor(0.1604)\n",
      "number of epoch 395 loss tensor(0.1604)\n",
      "number of epoch 396 loss tensor(0.1604)\n",
      "number of epoch 397 loss tensor(0.1604)\n",
      "number of epoch 398 loss tensor(0.1603)\n",
      "number of epoch 399 loss tensor(0.1603)\n",
      "number of epoch 400 loss tensor(0.1603)\n",
      "number of epoch 401 loss tensor(0.1603)\n",
      "number of epoch 402 loss tensor(0.1603)\n",
      "number of epoch 403 loss tensor(0.1602)\n",
      "number of epoch 404 loss tensor(0.1602)\n",
      "number of epoch 405 loss tensor(0.1602)\n",
      "number of epoch 406 loss tensor(0.1602)\n",
      "number of epoch 407 loss tensor(0.1601)\n",
      "number of epoch 408 loss tensor(0.1601)\n",
      "number of epoch 409 loss tensor(0.1601)\n",
      "number of epoch 410 loss tensor(0.1601)\n",
      "number of epoch 411 loss tensor(0.1601)\n",
      "number of epoch 412 loss tensor(0.1600)\n",
      "number of epoch 413 loss tensor(0.1600)\n",
      "number of epoch 414 loss tensor(0.1600)\n",
      "number of epoch 415 loss tensor(0.1600)\n",
      "number of epoch 416 loss tensor(0.1600)\n",
      "number of epoch 417 loss tensor(0.1599)\n",
      "number of epoch 418 loss tensor(0.1599)\n",
      "number of epoch 419 loss tensor(0.1599)\n",
      "number of epoch 420 loss tensor(0.1599)\n",
      "number of epoch 421 loss tensor(0.1599)\n",
      "number of epoch 422 loss tensor(0.1599)\n",
      "number of epoch 423 loss tensor(0.1598)\n",
      "number of epoch 424 loss tensor(0.1598)\n",
      "number of epoch 425 loss tensor(0.1598)\n",
      "number of epoch 426 loss tensor(0.1598)\n",
      "number of epoch 427 loss tensor(0.1598)\n",
      "number of epoch 428 loss tensor(0.1597)\n",
      "number of epoch 429 loss tensor(0.1597)\n",
      "number of epoch 430 loss tensor(0.1597)\n",
      "number of epoch 431 loss tensor(0.1597)\n",
      "number of epoch 432 loss tensor(0.1597)\n",
      "number of epoch 433 loss tensor(0.1597)\n",
      "number of epoch 434 loss tensor(0.1596)\n",
      "number of epoch 435 loss tensor(0.1596)\n",
      "number of epoch 436 loss tensor(0.1596)\n",
      "number of epoch 437 loss tensor(0.1596)\n",
      "number of epoch 438 loss tensor(0.1596)\n",
      "number of epoch 439 loss tensor(0.1596)\n",
      "number of epoch 440 loss tensor(0.1595)\n",
      "number of epoch 441 loss tensor(0.1595)\n",
      "number of epoch 442 loss tensor(0.1595)\n",
      "number of epoch 443 loss tensor(0.1595)\n",
      "number of epoch 444 loss tensor(0.1595)\n",
      "number of epoch 445 loss tensor(0.1595)\n",
      "number of epoch 446 loss tensor(0.1594)\n",
      "number of epoch 447 loss tensor(0.1594)\n",
      "number of epoch 448 loss tensor(0.1594)\n",
      "number of epoch 449 loss tensor(0.1594)\n",
      "number of epoch 450 loss tensor(0.1594)\n",
      "number of epoch 451 loss tensor(0.1594)\n",
      "number of epoch 452 loss tensor(0.1594)\n",
      "number of epoch 453 loss tensor(0.1593)\n",
      "number of epoch 454 loss tensor(0.1593)\n",
      "number of epoch 455 loss tensor(0.1593)\n",
      "number of epoch 456 loss tensor(0.1593)\n",
      "number of epoch 457 loss tensor(0.1593)\n",
      "number of epoch 458 loss tensor(0.1593)\n",
      "number of epoch 459 loss tensor(0.1593)\n",
      "number of epoch 460 loss tensor(0.1592)\n",
      "number of epoch 461 loss tensor(0.1592)\n",
      "number of epoch 462 loss tensor(0.1592)\n",
      "number of epoch 463 loss tensor(0.1592)\n",
      "number of epoch 464 loss tensor(0.1592)\n",
      "number of epoch 465 loss tensor(0.1592)\n",
      "number of epoch 466 loss tensor(0.1592)\n",
      "number of epoch 467 loss tensor(0.1592)\n",
      "number of epoch 468 loss tensor(0.1591)\n",
      "number of epoch 469 loss tensor(0.1591)\n",
      "number of epoch 470 loss tensor(0.1591)\n",
      "number of epoch 471 loss tensor(0.1591)\n",
      "number of epoch 472 loss tensor(0.1591)\n",
      "number of epoch 473 loss tensor(0.1591)\n",
      "number of epoch 474 loss tensor(0.1591)\n",
      "number of epoch 475 loss tensor(0.1591)\n",
      "number of epoch 476 loss tensor(0.1590)\n",
      "number of epoch 477 loss tensor(0.1590)\n",
      "number of epoch 478 loss tensor(0.1590)\n",
      "number of epoch 479 loss tensor(0.1590)\n",
      "number of epoch 480 loss tensor(0.1590)\n",
      "number of epoch 481 loss tensor(0.1590)\n",
      "number of epoch 482 loss tensor(0.1590)\n",
      "number of epoch 483 loss tensor(0.1590)\n",
      "number of epoch 484 loss tensor(0.1589)\n",
      "number of epoch 485 loss tensor(0.1589)\n",
      "number of epoch 486 loss tensor(0.1589)\n",
      "number of epoch 487 loss tensor(0.1589)\n",
      "number of epoch 488 loss tensor(0.1589)\n",
      "number of epoch 489 loss tensor(0.1589)\n",
      "number of epoch 490 loss tensor(0.1589)\n",
      "number of epoch 491 loss tensor(0.1589)\n",
      "number of epoch 492 loss tensor(0.1589)\n",
      "number of epoch 493 loss tensor(0.1588)\n",
      "number of epoch 494 loss tensor(0.1588)\n",
      "number of epoch 495 loss tensor(0.1588)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 496 loss tensor(0.1588)\n",
      "number of epoch 497 loss tensor(0.1588)\n",
      "number of epoch 498 loss tensor(0.1588)\n",
      "number of epoch 499 loss tensor(0.1588)\n",
      "number of epoch 500 loss tensor(0.1588)\n",
      "number of epoch 501 loss tensor(0.1588)\n",
      "number of epoch 502 loss tensor(0.1588)\n",
      "number of epoch 503 loss tensor(0.1587)\n",
      "number of epoch 504 loss tensor(0.1587)\n",
      "number of epoch 505 loss tensor(0.1587)\n",
      "number of epoch 506 loss tensor(0.1587)\n",
      "number of epoch 507 loss tensor(0.1587)\n",
      "number of epoch 508 loss tensor(0.1587)\n",
      "number of epoch 509 loss tensor(0.1587)\n",
      "number of epoch 510 loss tensor(0.1587)\n",
      "number of epoch 511 loss tensor(0.1587)\n",
      "number of epoch 512 loss tensor(0.1587)\n",
      "number of epoch 513 loss tensor(0.1586)\n",
      "number of epoch 514 loss tensor(0.1586)\n",
      "number of epoch 515 loss tensor(0.1586)\n",
      "number of epoch 516 loss tensor(0.1586)\n",
      "number of epoch 517 loss tensor(0.1586)\n",
      "number of epoch 518 loss tensor(0.1586)\n",
      "number of epoch 519 loss tensor(0.1586)\n",
      "number of epoch 520 loss tensor(0.1586)\n",
      "number of epoch 521 loss tensor(0.1586)\n",
      "number of epoch 522 loss tensor(0.1586)\n",
      "number of epoch 523 loss tensor(0.1586)\n",
      "number of epoch 524 loss tensor(0.1585)\n",
      "number of epoch 525 loss tensor(0.1585)\n",
      "number of epoch 526 loss tensor(0.1585)\n",
      "number of epoch 527 loss tensor(0.1585)\n",
      "number of epoch 528 loss tensor(0.1585)\n",
      "number of epoch 529 loss tensor(0.1585)\n",
      "number of epoch 530 loss tensor(0.1585)\n",
      "number of epoch 531 loss tensor(0.1585)\n",
      "number of epoch 532 loss tensor(0.1585)\n",
      "number of epoch 533 loss tensor(0.1585)\n",
      "number of epoch 534 loss tensor(0.1585)\n",
      "number of epoch 535 loss tensor(0.1585)\n",
      "number of epoch 536 loss tensor(0.1584)\n",
      "number of epoch 537 loss tensor(0.1584)\n",
      "number of epoch 538 loss tensor(0.1584)\n",
      "number of epoch 539 loss tensor(0.1584)\n",
      "number of epoch 540 loss tensor(0.1584)\n",
      "number of epoch 541 loss tensor(0.1584)\n",
      "number of epoch 542 loss tensor(0.1584)\n",
      "number of epoch 543 loss tensor(0.1584)\n",
      "number of epoch 544 loss tensor(0.1584)\n",
      "number of epoch 545 loss tensor(0.1584)\n",
      "number of epoch 546 loss tensor(0.1584)\n",
      "number of epoch 547 loss tensor(0.1584)\n",
      "number of epoch 548 loss tensor(0.1584)\n",
      "number of epoch 549 loss tensor(0.1584)\n",
      "number of epoch 550 loss tensor(0.1583)\n",
      "number of epoch 551 loss tensor(0.1583)\n",
      "number of epoch 552 loss tensor(0.1583)\n",
      "number of epoch 553 loss tensor(0.1583)\n",
      "number of epoch 554 loss tensor(0.1583)\n",
      "number of epoch 555 loss tensor(0.1583)\n",
      "number of epoch 556 loss tensor(0.1583)\n",
      "number of epoch 557 loss tensor(0.1583)\n",
      "number of epoch 558 loss tensor(0.1583)\n",
      "number of epoch 559 loss tensor(0.1583)\n",
      "number of epoch 560 loss tensor(0.1583)\n",
      "number of epoch 561 loss tensor(0.1583)\n",
      "number of epoch 562 loss tensor(0.1583)\n",
      "number of epoch 563 loss tensor(0.1583)\n",
      "number of epoch 564 loss tensor(0.1583)\n",
      "number of epoch 565 loss tensor(0.1582)\n",
      "number of epoch 566 loss tensor(0.1582)\n",
      "number of epoch 567 loss tensor(0.1582)\n",
      "number of epoch 568 loss tensor(0.1582)\n",
      "number of epoch 569 loss tensor(0.1582)\n",
      "number of epoch 570 loss tensor(0.1582)\n",
      "number of epoch 571 loss tensor(0.1582)\n",
      "number of epoch 572 loss tensor(0.1582)\n",
      "number of epoch 573 loss tensor(0.1582)\n",
      "number of epoch 574 loss tensor(0.1582)\n",
      "number of epoch 575 loss tensor(0.1582)\n",
      "number of epoch 576 loss tensor(0.1582)\n",
      "number of epoch 577 loss tensor(0.1582)\n",
      "number of epoch 578 loss tensor(0.1582)\n",
      "number of epoch 579 loss tensor(0.1582)\n",
      "number of epoch 580 loss tensor(0.1582)\n",
      "number of epoch 581 loss tensor(0.1582)\n",
      "number of epoch 582 loss tensor(0.1581)\n",
      "number of epoch 583 loss tensor(0.1581)\n",
      "number of epoch 584 loss tensor(0.1581)\n",
      "number of epoch 585 loss tensor(0.1581)\n",
      "number of epoch 586 loss tensor(0.1581)\n",
      "number of epoch 587 loss tensor(0.1581)\n",
      "number of epoch 588 loss tensor(0.1581)\n",
      "number of epoch 589 loss tensor(0.1581)\n",
      "number of epoch 590 loss tensor(0.1581)\n",
      "number of epoch 591 loss tensor(0.1581)\n",
      "number of epoch 592 loss tensor(0.1581)\n",
      "number of epoch 593 loss tensor(0.1581)\n",
      "number of epoch 594 loss tensor(0.1581)\n",
      "number of epoch 595 loss tensor(0.1581)\n",
      "number of epoch 596 loss tensor(0.1581)\n",
      "number of epoch 597 loss tensor(0.1581)\n",
      "number of epoch 598 loss tensor(0.1581)\n",
      "number of epoch 599 loss tensor(0.1581)\n",
      "number of epoch 600 loss tensor(0.1581)\n",
      "number of epoch 601 loss tensor(0.1580)\n",
      "number of epoch 602 loss tensor(0.1580)\n",
      "number of epoch 603 loss tensor(0.1580)\n",
      "number of epoch 604 loss tensor(0.1580)\n",
      "number of epoch 605 loss tensor(0.1580)\n",
      "number of epoch 606 loss tensor(0.1580)\n",
      "number of epoch 607 loss tensor(0.1580)\n",
      "number of epoch 608 loss tensor(0.1580)\n",
      "number of epoch 609 loss tensor(0.1580)\n",
      "number of epoch 610 loss tensor(0.1580)\n",
      "number of epoch 611 loss tensor(0.1580)\n",
      "number of epoch 612 loss tensor(0.1580)\n",
      "number of epoch 613 loss tensor(0.1580)\n",
      "number of epoch 614 loss tensor(0.1580)\n",
      "number of epoch 615 loss tensor(0.1580)\n",
      "number of epoch 616 loss tensor(0.1580)\n",
      "number of epoch 617 loss tensor(0.1580)\n",
      "number of epoch 618 loss tensor(0.1580)\n",
      "number of epoch 619 loss tensor(0.1580)\n",
      "number of epoch 620 loss tensor(0.1580)\n",
      "number of epoch 621 loss tensor(0.1580)\n",
      "number of epoch 622 loss tensor(0.1580)\n",
      "number of epoch 623 loss tensor(0.1579)\n",
      "number of epoch 624 loss tensor(0.1579)\n",
      "number of epoch 625 loss tensor(0.1579)\n",
      "number of epoch 626 loss tensor(0.1579)\n",
      "number of epoch 627 loss tensor(0.1579)\n",
      "number of epoch 628 loss tensor(0.1579)\n",
      "number of epoch 629 loss tensor(0.1579)\n",
      "number of epoch 630 loss tensor(0.1579)\n",
      "number of epoch 631 loss tensor(0.1579)\n",
      "number of epoch 632 loss tensor(0.1579)\n",
      "number of epoch 633 loss tensor(0.1579)\n",
      "number of epoch 634 loss tensor(0.1579)\n",
      "number of epoch 635 loss tensor(0.1579)\n",
      "number of epoch 636 loss tensor(0.1579)\n",
      "number of epoch 637 loss tensor(0.1579)\n",
      "number of epoch 638 loss tensor(0.1579)\n",
      "number of epoch 639 loss tensor(0.1579)\n",
      "number of epoch 640 loss tensor(0.1579)\n",
      "number of epoch 641 loss tensor(0.1579)\n",
      "number of epoch 642 loss tensor(0.1579)\n",
      "number of epoch 643 loss tensor(0.1579)\n",
      "number of epoch 644 loss tensor(0.1579)\n",
      "number of epoch 645 loss tensor(0.1579)\n",
      "number of epoch 646 loss tensor(0.1579)\n",
      "number of epoch 647 loss tensor(0.1579)\n",
      "number of epoch 648 loss tensor(0.1579)\n",
      "number of epoch 649 loss tensor(0.1579)\n",
      "number of epoch 650 loss tensor(0.1578)\n",
      "number of epoch 651 loss tensor(0.1578)\n",
      "number of epoch 652 loss tensor(0.1578)\n",
      "number of epoch 653 loss tensor(0.1578)\n",
      "number of epoch 654 loss tensor(0.1578)\n",
      "number of epoch 655 loss tensor(0.1578)\n",
      "number of epoch 656 loss tensor(0.1578)\n",
      "number of epoch 657 loss tensor(0.1578)\n",
      "number of epoch 658 loss tensor(0.1578)\n",
      "number of epoch 659 loss tensor(0.1578)\n",
      "number of epoch 660 loss tensor(0.1578)\n",
      "number of epoch 661 loss tensor(0.1578)\n",
      "number of epoch 662 loss tensor(0.1578)\n",
      "number of epoch 663 loss tensor(0.1578)\n",
      "number of epoch 664 loss tensor(0.1578)\n",
      "number of epoch 665 loss tensor(0.1578)\n",
      "number of epoch 666 loss tensor(0.1578)\n",
      "number of epoch 667 loss tensor(0.1578)\n",
      "number of epoch 668 loss tensor(0.1578)\n",
      "number of epoch 669 loss tensor(0.1578)\n",
      "number of epoch 670 loss tensor(0.1578)\n",
      "number of epoch 671 loss tensor(0.1578)\n",
      "number of epoch 672 loss tensor(0.1578)\n",
      "number of epoch 673 loss tensor(0.1578)\n",
      "number of epoch 674 loss tensor(0.1578)\n",
      "number of epoch 675 loss tensor(0.1578)\n",
      "number of epoch 676 loss tensor(0.1578)\n",
      "number of epoch 677 loss tensor(0.1578)\n",
      "number of epoch 678 loss tensor(0.1578)\n",
      "number of epoch 679 loss tensor(0.1578)\n",
      "number of epoch 680 loss tensor(0.1578)\n",
      "number of epoch 681 loss tensor(0.1578)\n",
      "number of epoch 682 loss tensor(0.1577)\n",
      "number of epoch 683 loss tensor(0.1577)\n",
      "number of epoch 684 loss tensor(0.1577)\n",
      "number of epoch 685 loss tensor(0.1577)\n",
      "number of epoch 686 loss tensor(0.1577)\n",
      "number of epoch 687 loss tensor(0.1577)\n",
      "number of epoch 688 loss tensor(0.1577)\n",
      "number of epoch 689 loss tensor(0.1577)\n",
      "number of epoch 690 loss tensor(0.1577)\n",
      "number of epoch 691 loss tensor(0.1577)\n",
      "number of epoch 692 loss tensor(0.1577)\n",
      "number of epoch 693 loss tensor(0.1577)\n",
      "number of epoch 694 loss tensor(0.1577)\n",
      "number of epoch 695 loss tensor(0.1577)\n",
      "number of epoch 696 loss tensor(0.1577)\n",
      "number of epoch 697 loss tensor(0.1577)\n",
      "number of epoch 698 loss tensor(0.1577)\n",
      "number of epoch 699 loss tensor(0.1577)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for epoch in range(EPOCH):\n",
    "    encoded, decoded = autoencoder(x_data)\n",
    "    \n",
    "    loss = loss_fun(decoded,x_data)\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()     \n",
    "    \n",
    "\n",
    "    if epoch in range(EPOCH):\n",
    "        print('number of epoch', epoch, 'loss', loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Latent space')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data_array = encoded.detach().numpy()\n",
    "\n",
    "plt.scatter(data_array[:,0],data_array[:,1])\n",
    "plt.title(\"Latent space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33600873 0.29912153]\n",
      " [0.33290225 0.30417842]\n",
      " [0.32529885 0.31995854]\n",
      " [0.32485482 0.32072598]\n",
      " [0.32627222 0.3192973 ]\n",
      " [0.32085174 0.3217566 ]\n",
      " [0.31275767 0.32575879]\n",
      " [0.31118605 0.32646775]\n",
      " [0.302972   0.3273351 ]\n",
      " [0.20955992 0.3642238 ]\n",
      " [0.10005118 0.30741996]\n",
      " [0.28017205 0.32735533]\n",
      " [0.2929356  0.32393357]\n",
      " [0.3069541  0.32069308]\n",
      " [0.3224649  0.3127916 ]\n",
      " [0.319755   0.32750294]\n",
      " [0.3245016  0.3204335 ]\n",
      " [0.32190907 0.32026303]\n",
      " [0.31587362 0.34292468]\n",
      " [0.31519595 0.35279912]\n",
      " [0.31691903 0.35067588]\n",
      " [0.31904203 0.35256228]\n",
      " [0.32985798 0.3377975 ]\n",
      " [0.32554555 0.32731217]\n",
      " [0.31496727 0.31938195]\n",
      " [0.29637003 0.31837562]\n",
      " [0.3070456  0.31177002]\n",
      " [0.32509965 0.30260235]\n",
      " [0.31491292 0.2977848 ]\n",
      " [0.29673517 0.30301118]\n",
      " [0.31565624 0.29512137]\n",
      " [0.31916082 0.2890228 ]\n",
      " [0.30548707 0.2976804 ]\n",
      " [0.19504088 0.34117657]\n",
      " [0.07568535 0.28408733]\n",
      " [0.26538402 0.30403376]\n",
      " [0.28419036 0.30335647]\n",
      " [0.29718646 0.30851325]\n",
      " [0.29241613 0.3062144 ]\n",
      " [0.         0.3455044 ]\n",
      " [0.3405854  0.27298248]\n",
      " [0.35972324 0.25731307]\n",
      " [0.35823727 0.26181442]\n",
      " [0.36230344 0.26093394]\n",
      " [0.36425728 0.264807  ]\n",
      " [0.35640284 0.2696392 ]\n",
      " [0.3593415  0.26809317]\n",
      " [0.36676005 0.2642271 ]\n",
      " [0.34564084 0.27683502]\n",
      " [0.34183115 0.28623337]\n",
      " [0.29954037 0.29435202]\n",
      " [0.32483655 0.29814968]\n",
      " [0.32870927 0.30630577]\n",
      " [0.29821306 0.31669313]\n",
      " [0.32444224 0.30819553]\n",
      " [0.31829512 0.3104328 ]\n",
      " [0.30833602 0.3179379 ]\n",
      " [0.20494694 0.37291574]\n",
      " [0.1197159  0.3020398 ]\n",
      " [0.298455   0.30560285]\n",
      " [0.2845022  0.32271418]\n",
      " [0.2918946  0.3171578 ]\n",
      " [0.2953475  0.31335774]\n",
      " [0.3178063  0.2944485 ]\n",
      " [0.33400437 0.29247   ]\n",
      " [0.35470667 0.2785846 ]\n",
      " [0.37707335 0.2626802 ]\n",
      " [0.37899846 0.2612481 ]\n",
      " [0.3730932  0.27229068]\n",
      " [0.37597683 0.26878065]\n",
      " [0.37075967 0.27165675]\n",
      " [0.36467686 0.2789659 ]\n",
      " [0.35862005 0.28193253]\n",
      " [0.34994093 0.28438953]\n",
      " [0.34765744 0.28700632]\n",
      " [0.34363973 0.28970352]\n",
      " [0.34880018 0.29441768]\n",
      " [0.34939963 0.3010063 ]\n",
      " [0.3384012  0.31960514]\n",
      " [0.34288442 0.313476  ]\n",
      " [0.33376265 0.32615948]\n",
      " [0.22583416 0.39160728]\n",
      " [0.15552455 0.3076011 ]\n",
      " [0.3242318  0.32640922]\n",
      " [0.31441998 0.32993236]\n",
      " [0.31195337 0.33027828]\n",
      " [0.32599044 0.32881597]\n",
      " [0.33125174 0.3277825 ]\n",
      " [0.34491843 0.3199358 ]\n",
      " [0.35638782 0.31159437]\n",
      " [0.37198    0.2962435 ]\n",
      " [0.3828733  0.27739277]\n",
      " [0.38917312 0.26856202]\n",
      " [0.3902309  0.26762673]\n",
      " [0.38663948 0.2723289 ]\n",
      " [0.382858   0.27405894]\n",
      " [0.37046158 0.29531056]\n",
      " [0.34611714 0.3107316 ]\n",
      " [0.3392741  0.31566903]\n",
      " [0.3567284  0.31530493]\n",
      " [0.3633069  0.3132717 ]\n",
      " [0.35225427 0.32501352]\n",
      " [0.35214046 0.32053643]\n",
      " [0.34563792 0.3262789 ]\n",
      " [0.34237686 0.33402023]\n",
      " [0.24264476 0.38147682]\n",
      " [0.15449521 0.3197693 ]\n",
      " [0.33039314 0.33695903]\n",
      " [0.33118492 0.34081268]\n",
      " [0.32804    0.33774984]\n",
      " [0.29614395 0.3307754 ]\n",
      " [0.28868473 0.30178943]\n",
      " [0.33733428 0.29379976]\n",
      " [0.3698536  0.27858934]\n",
      " [0.3885147  0.2797365 ]\n",
      " [0.39154616 0.28240335]\n",
      " [0.39421034 0.27696013]\n",
      " [0.4014387  0.27281412]\n",
      " [0.40092844 0.27793267]\n",
      " [0.39051783 0.28915542]\n",
      " [0.34433264 0.3018271 ]\n",
      " [0.32140434 0.30652416]\n",
      " [0.33008882 0.32988667]\n",
      " [0.3538612  0.33204564]\n",
      " [0.3582366  0.3368519 ]\n",
      " [0.36519846 0.33829468]\n",
      " [0.35215777 0.34794366]\n",
      " [0.35950148 0.3328756 ]\n",
      " [0.3462851  0.3298726 ]\n",
      " [0.2499288  0.37323776]\n",
      " [0.15303794 0.31332982]\n",
      " [0.32669103 0.32964692]\n",
      " [0.32479095 0.33467984]\n",
      " [0.32106173 0.33888775]\n",
      " [0.31709898 0.32941705]\n",
      " [0.3218595  0.31965092]\n",
      " [0.3429292  0.28899926]\n",
      " [0.38065556 0.26778078]\n",
      " [0.40219933 0.2534062 ]\n",
      " [0.3965552  0.2550809 ]\n",
      " [0.41007566 0.23549317]\n",
      " [0.42124546 0.22155188]\n",
      " [0.4153435  0.22526388]\n",
      " [0.41702846 0.22450142]\n",
      " [0.39800137 0.25185513]\n",
      " [0.37719494 0.2889718 ]\n",
      " [0.38024026 0.28865138]\n",
      " [0.34937912 0.29417786]\n",
      " [0.37440705 0.29743266]\n",
      " [0.37291008 0.29957247]\n",
      " [0.36463463 0.30868042]\n",
      " [0.36235264 0.30450505]\n",
      " [0.35128206 0.30830678]\n",
      " [0.2481153  0.35427684]\n",
      " [0.15176582 0.2853942 ]\n",
      " [0.31745952 0.3069389 ]\n",
      " [0.32224184 0.30332297]\n",
      " [0.32144597 0.31792796]\n",
      " [0.30973232 0.3079824 ]\n",
      " [0.28768897 0.29478177]\n",
      " [0.3535911  0.2752738 ]\n",
      " [0.38212863 0.268317  ]\n",
      " [0.4049161  0.2588839 ]\n",
      " [0.4089593  0.2537728 ]\n",
      " [0.40818292 0.26113945]\n",
      " [0.41654187 0.21767329]\n",
      " [0.4237245  0.20817073]\n",
      " [0.42345122 0.19762342]\n",
      " [0.392402   0.19634947]\n",
      " [0.34109193 0.24947461]\n",
      " [0.3278963  0.2894944 ]\n",
      " [0.35078394 0.29356945]\n",
      " [0.36394042 0.28736654]\n",
      " [0.35303238 0.31047064]\n",
      " [0.35288584 0.31051648]\n",
      " [0.36033666 0.31035674]\n",
      " [0.35828823 0.3025047 ]\n",
      " [0.25605723 0.34742194]\n",
      " [0.15431708 0.29286885]\n",
      " [0.32886162 0.30943924]\n",
      " [0.32722187 0.30754656]\n",
      " [0.32772428 0.31651887]\n",
      " [0.31068656 0.3081254 ]\n",
      " [0.29370397 0.29485872]\n",
      " [0.35480043 0.27711213]\n",
      " [0.38423312 0.27472585]\n",
      " [0.40245757 0.261504  ]\n",
      " [0.40445995 0.27022013]\n",
      " [0.4072786  0.2577708 ]\n",
      " [0.41679212 0.21721086]\n",
      " [0.41953966 0.25380218]\n",
      " [0.41493216 0.2514803 ]\n",
      " [0.3895734  0.25390542]\n",
      " [0.3664316  0.26536217]\n",
      " [0.36125076 0.27456123]\n",
      " [0.36306745 0.30805686]\n",
      " [0.3582749  0.3304349 ]\n",
      " [0.3483261  0.34368718]\n",
      " [0.34398636 0.3510726 ]\n",
      " [0.3484428  0.34839803]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.4114, 0.2755,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4012, 0.2822,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4062, 0.2789,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.4012, 0.2822,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4050, 0.2797,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4012, 0.2822,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ThresholdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
