{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# loading data\n",
    "data_white = pd.read_csv(\"../app/static/data/winequality-white.csv\", sep =\";\")\n",
    "data_red = pd.read_csv(\"../app/static/data/winequality-red.csv\", sep =\";\")\n",
    "data = pd.concat([data_red, data_white])\n",
    "df = data.drop(columns=['quality'])\n",
    "\n",
    "# data noramlization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(df.astype(float))\n",
    "df = pd.DataFrame(x_scaled)\n",
    "\n",
    "x_data = df.to_numpy()\n",
    "x_data = torch.Tensor(x_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(11, 6),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6, 2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 6),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6, 11),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        return z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder:\n",
    "    \n",
    "    def fn_train(self, x_data, num_epochs):\n",
    "              \n",
    "        self.model = EncoderDecoder()\n",
    "        loss_fun = nn.MSELoss()\n",
    "        opt= torch.optim.SGD(self.model.parameters(),lr=0.01)\n",
    "        \n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            encoded, decoded = self.model(x_data)\n",
    "            # calculate loss\n",
    "            loss = loss_fun(decoded,x_data)                        \n",
    "            # clear previous gradients\n",
    "            opt.zero_grad()      \n",
    "            # compute gradients of all variables wrt loss                                       \n",
    "            loss.backward()  \n",
    "            # perform updates using calculated gradients                                           \n",
    "            opt.step()\n",
    "            print(f'loss {epoch} = {loss}')\n",
    "        return encoded, decoded\n",
    "    \n",
    "    def data_projection(self, x_data):\n",
    "        encoded, decoded = self.model(x_data)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSpace:\n",
    "\n",
    "    def qm_mse_dist(self, original, reduced):\n",
    "        # mean squared error of distances\n",
    "        hd_dists = euclidean_distances(original)\n",
    "        ld_dists = euclidean_distances(reduced)\n",
    "        total_squared_error = np.sum((hd_dists - ld_dists) ** 2)\n",
    "        return total_squared_error / original.shape[0]\n",
    "    \n",
    "    def get_latent(self):\n",
    "        # train model\n",
    "        ae = AutoEncoder()\n",
    "        encoded, decoded  = ae.fn_train(x_data, 20)\n",
    "        # convert the latent variable z into dataframe\n",
    "        z = encoded.data.numpy()\n",
    "        df_z = pd.DataFrame({'x':z[:,0], 'y':z[:, 1], 'label':data['quality'], 'is_trained':'no'})\n",
    "        # quality measures. All points. Projection 1:\n",
    "        self.decoded = decoded.detach().cpu().numpy()\n",
    "        qm_mse_all_pr1 = round(self.qm_mse_dist(x_data, self.decoded), 4)\n",
    "        return df_z, qm_mse_all_pr1\n",
    "    \n",
    "    def projection(self, points):\n",
    "        # filter the selected points\n",
    "        selected_points = x_data[points]\n",
    "        \n",
    "        # get a latent space z of the selected points\n",
    "        encoded_selected, decoded_selected = self.ae.fn_train(selected_points, 1)\n",
    "        z_selected = encoded_selected.data.numpy()\n",
    "        df_yes = pd.DataFrame({'x':z_selected[:,0], 'y':z_selected[:, 1], 'label':data['quality'].iloc[points], 'is_trained':'yes'})\n",
    "        \n",
    "        # get a latent space z of the all points\n",
    "        encoded_all_points, decoded_all_points = self.ae.data_projection(x_data)\n",
    "        z_all_points = encoded_all_points.data.numpy()\n",
    "        \n",
    "        # all points except selected \n",
    "        arr_no = np.delete(z_all_points, [points], axis=0)\n",
    "        labels = data['quality'].to_numpy()\n",
    "        arr_no_labels = np.delete(labels, [points])\n",
    "        df_no = pd.DataFrame({'x':arr_no[:,0], 'y':arr_no[:, 1], 'label':arr_no_labels, 'is_trained':'no'})\n",
    "        projection = pd.concat([df_yes, df_no])\n",
    "        \n",
    "        ## quality measures##\n",
    "        # selected points. Projection 1:\n",
    "        qm_mse_selected_pr1 = round(self.qm_mse_dist(selected_points, self.decoded[points]), 4)\n",
    "        # all points. Projection 2:\n",
    "        decoded_all_points = decoded_all_points.detach().cpu().numpy()\n",
    "        qm_mse_all_points_pr2 = round(self.qm_mse_dist(x_data, decoded_all_points), 4)\n",
    "        # selected points. Projection 2:\n",
    "        decoded_selected = decoded_selected.detach().cpu().numpy()\n",
    "        qm_mse_selected_pr2 = round(self.qm_mse_dist(selected_points, decoded_selected), 4)        \n",
    "        return projection, qm_mse_selected_pr1, qm_mse_all_points_pr2, qm_mse_selected_pr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1 = 0.05338186398148537\n",
      "loss 2 = 0.053329840302467346\n",
      "loss 3 = 0.05327829346060753\n",
      "loss 4 = 0.05322721600532532\n",
      "loss 5 = 0.053176604211330414\n",
      "loss 6 = 0.05312645435333252\n",
      "loss 7 = 0.053076766431331635\n",
      "loss 8 = 0.05302752926945686\n",
      "loss 9 = 0.052978742867708206\n",
      "loss 10 = 0.052930399775505066\n",
      "loss 11 = 0.05288249999284744\n",
      "loss 12 = 0.05283503979444504\n",
      "loss 13 = 0.052788011729717255\n",
      "loss 14 = 0.052741412073373795\n",
      "loss 15 = 0.05269524082541466\n",
      "loss 16 = 0.05264949053525925\n",
      "loss 17 = 0.052604157477617264\n",
      "loss 18 = 0.05255924165248871\n",
      "loss 19 = 0.052514735609292984\n",
      "loss 20 = 0.05247063562273979\n",
      "             x         y  label is_trained\n",
      "0    -0.002314 -0.001984      5         no\n",
      "1    -0.002333 -0.002128      5         no\n",
      "2    -0.002321 -0.002113      5         no\n",
      "3    -0.002946 -0.002166      6         no\n",
      "4    -0.002314 -0.001984      5         no\n",
      "...        ...       ...    ...        ...\n",
      "4893 -0.003427 -0.001685      6         no\n",
      "4894 -0.003818 -0.001682      5         no\n",
      "4895 -0.003163 -0.001757      6         no\n",
      "4896 -0.003865 -0.001557      7         no\n",
      "4897 -0.003821 -0.001619      6         no\n",
      "\n",
      "[7373 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "instance = LatentSpace()\n",
    "output = instance.get_latent()\n",
    "output_data = output[0]\n",
    "projection = output[0]\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
