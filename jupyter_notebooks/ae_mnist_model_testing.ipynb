{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, cuda, optim, tensor\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='../app/mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, 12), \n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(12, 2)\n",
    "        )\n",
    "        # decoder part\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 12),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(128, 28 * 28), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        return z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder:\n",
    "    \n",
    "    def fn_train(self, data, num_epochs):\n",
    "        \n",
    "        self.model = EncoderDecoder()        \n",
    "        if torch.cuda.is_available():\n",
    "            self.model.cuda()\n",
    "            \n",
    "        batch_size = 100\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(int(data.shape[0] / batch_size)):\n",
    "                batch = data[i * batch_size:(i + 1) * batch_size]\n",
    "                batch = tensor(batch, dtype=torch.float)\n",
    "                if cuda.is_available():\n",
    "                    batch = batch.cuda()\n",
    "                # ===================forward=====================\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                encoded, decoded = self.model(batch)\n",
    "                # calculate the loss\n",
    "                loss = criterion(decoded, batch)\n",
    "                # ===================backward====================\n",
    "                # clear the gradients of all optimized variables\n",
    "                optimizer.zero_grad()\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "        data = tensor(data, dtype=torch.float)\n",
    "        if cuda.is_available():\n",
    "            data = data.cuda()\n",
    "        encoded, decoded = self.model(data)\n",
    "        if cuda.is_available():\n",
    "            encoded = encoded.cpu()\n",
    "            decoded = decoded.cpu()\n",
    "        return encoded.detach().numpy(), decoded.detach().numpy()\n",
    "\n",
    "    def data_projection(self, x_data):\n",
    "        encoded, decoded = self.model(x_data)\n",
    "        return encoded, decoded\n",
    "    \n",
    "    def img_fn(self):\n",
    "        # obtain one batch of test images\n",
    "        dataiter = iter(test_loader)\n",
    "        images, labels = dataiter.next()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images_flatten = images.view(images.size(0), -1)\n",
    "            images_flatten = images_flatten.cuda()\n",
    "            # get sample outputs\n",
    "            encoded, decoded = self.model(images_flatten)\n",
    "            # prep images for display\n",
    "            return decoded, images.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start projection training\n",
      "Training done 5.849467336000089\n",
      "(array([[ 0.6833365 , -1.1703335 ],\n",
      "       [ 1.6832031 , -0.42967546],\n",
      "       [ 0.14373209, -0.8071306 ],\n",
      "       ...,\n",
      "       [-0.17171516, -1.3081797 ],\n",
      "       [ 0.8014802 , -0.6141271 ],\n",
      "       [-1.3357732 , -1.173598  ]], dtype=float32), array([[-9.05147847e-03, -3.01710726e-03,  1.08721033e-02, ...,\n",
      "         5.23970881e-03, -5.43999206e-03,  6.00954751e-03],\n",
      "       [-1.01989992e-02, -3.59269930e-03, -1.22585120e-02, ...,\n",
      "         1.70369875e-02, -1.09606115e-02,  4.10939101e-03],\n",
      "       [-2.03931406e-02, -3.28817149e-03, -1.04504405e-02, ...,\n",
      "        -5.28144790e-03, -8.29700287e-03, -9.66230407e-03],\n",
      "       ...,\n",
      "       [-6.15663768e-04,  5.70841075e-04, -4.84520523e-03, ...,\n",
      "         3.09552997e-05, -9.51757561e-03, -9.84099344e-04],\n",
      "       [-8.96656699e-03, -2.21567973e-03, -1.11383321e-02, ...,\n",
      "         7.22291134e-03, -8.49894062e-03,  1.12378560e-02],\n",
      "       [ 3.54703143e-03,  8.68346728e-03, -7.77987344e-03, ...,\n",
      "         8.52328725e-03,  3.09721590e-03, -6.17783749e-03]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "train_dataset = datasets.MNIST(root='../app/mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=10000000)\n",
    "\n",
    "print('Start projection training')\n",
    "ae = AutoEncoder()\n",
    "\n",
    "for data in train_loader:\n",
    "    data = data[0].numpy()\n",
    "    data = data\n",
    "    data = data.reshape((data.shape[0], -1))\n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    dim_reducted = ae.fn_train(data,  1)\n",
    "    print('Training done', timeit.default_timer() - start_time)\n",
    "    print(dim_reducted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded, images = ae.img_fn()\n",
    "# output is resized into a batch of images\n",
    "output = decoded.view(128, 1, 28, 28)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().cpu().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_t = dim_reducted[0]\n",
    "encoded_t = encoded_t[0:64]\n",
    "z_t = tensor(encoded_t, dtype=torch.float)\n",
    "z_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "with torch.no_grad():    \n",
    "    z_t = z_t.cuda()\n",
    "    sample = ae.model.decoder(z_t).cpu()    \n",
    "    save_image(sample.view(64, 1, 28, 28), './results/vae_sample_' + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
